<!DOCTYPE html>
<html lang="en">
  <head>
    
<meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>


<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />



  <meta name="description" content="Scrapy学习日记 一 · run many spiders"/>




  <meta name="keywords" content="Python,Scrapy," />




  <link rel="alternate" href="/atom.xml" title="linw1995">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=2.3.x" />



<link rel="canonical" href="http://linw1995.com/2017/04/15/Scrapy学习日记-一-·-run-many-spiders/"/>


<meta name="description" content="这两周都在学习使用这个爬虫框架，略有收获。把一些小技巧分享给大家。">
<meta property="og:type" content="article">
<meta property="og:title" content="Scrapy学习日记 一 · run many spiders">
<meta property="og:url" content="http://linw1995.com/2017/04/15/Scrapy学习日记-一-·-run-many-spiders/index.html">
<meta property="og:site_name" content="linw1995">
<meta property="og:description" content="这两周都在学习使用这个爬虫框架，略有收获。把一些小技巧分享给大家。">
<meta property="og:updated_time" content="2017-04-17T04:46:02.151Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Scrapy学习日记 一 · run many spiders">
<meta name="twitter:description" content="这两周都在学习使用这个爬虫框架，略有收获。把一些小技巧分享给大家。">


<link rel="stylesheet" type="text/css" href="/css/style.css?v=2.3.x" />



  <link rel="stylesheet" type="text/css" href="/lib/fancybox/jquery.fancybox.css" />





<script>
  var CONFIG = {
    search: false,
    searchPath: "/search.xml",
    fancybox: true,
    toc: true,
  }
</script>




  

  <script type="text/javascript">
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

        ga('create', 'UA-86170223-1', 'auto');
        ga('send', 'pageview');
  </script>



    <title> Scrapy学习日记 一 · run many spiders · linw1995 </title>
  </head>

  <body><div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/." class="logo">linw1995</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>

<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    
      <a href="/">
        <li class="mobile-menu-item">
          
          
            Home
          
        </li>
      </a>
    
      <a href="/archives/">
        <li class="mobile-menu-item">
          
          
            Archives
          
        </li>
      </a>
    
      <a href="/tags">
        <li class="mobile-menu-item">
          
          
            Tags
          
        </li>
      </a>
    
      <a href="/categories">
        <li class="mobile-menu-item">
          
          
            Categories
          
        </li>
      </a>
    
  </ul>
</nav>

    <div class="container" id="mobile-panel">
      <header id="header" class="header"><div class="logo-wrapper">
  <a href="/." class="logo">linw1995</a>
</div>

<nav class="site-navbar">
  
    <ul id="menu" class="menu">
      
        <li class="menu-item">
          <a class="menu-item-link" href="/">
            
            
              Home
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/archives/">
            
            
              Archives
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/tags">
            
            
              Tags
            
          </a>
        </li>
      
        <li class="menu-item">
          <a class="menu-item-link" href="/categories">
            
            
              Categories
            
          </a>
        </li>
      
      
    </ul>
  
</nav>

      </header>

      <main id="main" class="main">
        <div class="content-wrapper">
          <div id="content" class="content">
            
  
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          Scrapy学习日记 一 · run many spiders
        
      </h1>

      <div class="post-meta">
        <span class="post-time">
          Apr 15, 2017
        </span>
      </div>
    </header>

    
    
  <div class="post-toc" id="post-toc">
    <h2 class="post-toc-title">Contents</h2>
    <div class="post-toc-content">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#template-自定模板"><span class="toc-text">template 自定模板</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#command-自定命令"><span class="toc-text">command 自定命令</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#job-Spider的暂停-恢复"><span class="toc-text">job Spider的暂停\恢复</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#结论"><span class="toc-text">结论</span></a></li></ol>
    </div>
  </div>


    <div class="post-content">
      
        <p>这两周都在学习使用这个爬虫框架，略有收获。<br>把一些小技巧分享给大家。<br><a id="more"></a></p>
<h1 id="template-自定模板"><a href="#template-自定模板" class="headerlink" title="template 自定模板"></a>template 自定模板</h1><p>用过<strong>Scrapy</strong>的人都知道，有生成<strong>Spider</strong>的命令</p>
<pre><code>scrapy genspider mydomain mydomain.com
</code></pre><p>其实我们可以自定模板，然后一样通过这个命令生成出爬虫。</p>
<!-- markdownlint-disable MD022 MD012 -->
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"># common.tmpl</div><div class="line"># -*- coding: utf-8 -*-</div><div class="line">import scrapy</div><div class="line"></div><div class="line"></div><div class="line">class $classname(scrapy.Spider):</div><div class="line">    name = &quot;$name&quot;</div><div class="line">    allowed_domains = [&quot;$domain&quot;]</div><div class="line">    start_urls = [&apos;http://$domain/&apos;]</div><div class="line"></div><div class="line">    def parse(self, response):</div><div class="line">        pass</div></pre></td></tr></table></figure>
<!-- markdownlint-enable MD022 MD012-->
<p>在根目录下创建新的文件夹来存放自定模板,再把写好的common.tmpl保存到里面</p>
<pre><code>scrapy.cfg
myprojec/
    __init__.py
    items.py
    pipelines.py
    settings.py
    templates/
        spiders/
            common.tmpl
    spiders/
        __init__.py
        spider1.py
        spider2.py
        ...
</code></pre><p>然后修改设置，添加TEMPLATES_DIR<br><!-- markdownlint-disable MD022 MD026 --></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># settings.py</span></div><div class="line"><span class="comment"># -*- coding:utf-8 -*-</span></div><div class="line"><span class="keyword">from</span> os <span class="keyword">import</span> path</div><div class="line"><span class="comment"># ...</span></div><div class="line"></div><div class="line">basedir = os.path.dirname(__file__)</div><div class="line">TEMPLATES_DIR = os.path.abspath os.path.join(basedir, <span class="string">'templates'</span>))</div><div class="line"><span class="comment"># ...</span></div></pre></td></tr></table></figure>
<!-- markdownlint-enable MD022 MD026-->
<p>然后即可使用该命令生成<strong>Spider</strong>了</p>
<pre><code>scrapy genspider -t common mydomain mydomain.com
</code></pre><h1 id="command-自定命令"><a href="#command-自定命令" class="headerlink" title="command 自定命令"></a>command 自定命令</h1><p>用<strong>template</strong>模板生成了大量的<strong>Spider</strong>,想要用一个命令让他们一起运行怎么办。<br>通过自定<strong>command</strong>,满足你的</p>
<!-- markdownlint-disable MD022 MD026 MD012 -->
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># runallspider.py</span></div><div class="line"><span class="comment"># -*- coding:utf-8 -*-</span></div><div class="line"><span class="keyword">from</span> scrapy.commands <span class="keyword">import</span> ScrapyCommand</div><div class="line"></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Command</span><span class="params">(ScrapyCommand)</span>:</span></div><div class="line"></div><div class="line">    requires_project = <span class="keyword">True</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">syntax</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="keyword">return</span> <span class="string">'[options]'</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">short_desc</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="keyword">return</span> <span class="string">'Runs all of the spiders'</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self, args, opts)</span>:</span></div><div class="line">        <span class="keyword">for</span> spider_name <span class="keyword">in</span> self.crawler_process.spider_loader.list():</div><div class="line">            self.crawler_process.crawl(spider_name)</div><div class="line">        self.crawler_process.start()</div></pre></td></tr></table></figure>
<!-- markdownlint-enable MD022 MD026 MD012 -->
<p>也同<strong>template</strong>一样，在根目录下创建一文件夹commands，把写好的runallspider.py保存到里面去<br>然后修改设置，添加COMMANDS_MODULE<br><!-- markdownlint-disable MD022 MD026 --></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># settings.py</span></div><div class="line"><span class="comment"># ...</span></div><div class="line">COMMANDS_MODULE = <span class="string">'myproject.commands'</span></div><div class="line"><span class="comment"># ...</span></div></pre></td></tr></table></figure>
<!-- markdownlint-enable MD022 MD026 -->
<p>然后即可使用该命令同时运行所有<strong>Spider</strong>了</p>
<pre><code>scrapy runallspider
</code></pre><h1 id="job-Spider的暂停-恢复"><a href="#job-Spider的暂停-恢复" class="headerlink" title="job Spider的暂停\恢复"></a>job Spider的暂停\恢复</h1><p>和<strong>Linux</strong>系统下的<strong>job</strong>命令类似，用来保存<strong>Spider</strong>状态，以下次启动<strong>Spider</strong>来恢复之前的保存的爬取状态</p>
<p>首先要修改设置，添加JOBDIR<br><!-- markdownlint-disable MD022 MD026 --></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># settings.py</span></div><div class="line"><span class="comment"># ...</span></div><div class="line">JOBDIR = os.path.abspath os.path.join(basedir, <span class="string">'jobs'</span>))</div><div class="line"><span class="comment"># ...</span></div></pre></td></tr></table></figure>
<!-- markdownlint-enable MD022 MD026 -->
<p>然后像往常一样运行爬虫即可，也可以通过重载设置来临时使用</p>
<pre><code>scrapy crawl spider -s JOBDIR=jobs/spider
</code></pre><p>爬虫暂停后，也是通过以上命令恢复到之前保存的状态</p>
<p>可是现在我们运行<code>scrapy runallspider</code>命令就会出错，这是因为<strong>Scrapy</strong>设计时只考虑运行单例<strong>Spider</strong><br>我们只需对存储<strong>Spider</strong>状态的类代码进行修改，使其能满足我们的要求</p>
<!-- markdownlint-disable MD022 MD026 MD012 -->
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># ext/__init__.py</span></div><div class="line"><span class="comment"># -*- coding: utf - 8 - *-</span></div><div class="line"><span class="keyword">import</span> logging</div><div class="line"><span class="keyword">import</span> os</div><div class="line"><span class="keyword">import</span> pickle</div><div class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</div><div class="line"><span class="keyword">from</span> twisted.internet <span class="keyword">import</span> task</div><div class="line"></div><div class="line"><span class="keyword">from</span> scrapy.core.scheduler <span class="keyword">import</span> Scheduler <span class="keyword">as</span> SchedulerBase</div><div class="line"><span class="keyword">from</span> scrapy.dupefilters <span class="keyword">import</span> RFPDupeFilter <span class="keyword">as</span> RFPDupeFilterBase</div><div class="line"><span class="keyword">from</span> scrapy.extensions.logstats <span class="keyword">import</span> LogStats <span class="keyword">as</span> LogStatsBase</div><div class="line"><span class="keyword">from</span> scrapy.extensions.spiderstate <span class="keyword">import</span> SpiderState <span class="keyword">as</span> SpiderStateBase</div><div class="line"><span class="keyword">from</span> scrapy.utils.job <span class="keyword">import</span> job_dir</div><div class="line"><span class="keyword">from</span> scrapy.utils.misc <span class="keyword">import</span> load_object</div><div class="line"></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">StatsCollector</span>:</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, crawler)</span>:</span></div><div class="line">        self._dump = crawler.settings.getbool(<span class="string">'STATS_DUMP'</span>)</div><div class="line">        self._stats = defaultdict(dict)</div><div class="line">        self.jobdir = job_dir(crawler.settings)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_value</span><span class="params">(self, key, default=None, spider=None)</span>:</span></div><div class="line">        <span class="keyword">return</span> self._stats[spider.name <span class="keyword">if</span> spider <span class="keyword">else</span> <span class="keyword">None</span>].get(key, default)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_stats</span><span class="params">(self, spider=None)</span>:</span></div><div class="line">        <span class="keyword">return</span> self._stats[spider.name <span class="keyword">if</span> spider <span class="keyword">else</span> <span class="keyword">None</span>]</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_all_stats</span><span class="params">(self)</span>:</span></div><div class="line">        <span class="keyword">return</span> self._stats</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">set_value</span><span class="params">(self, key, value, spider=None)</span>:</span></div><div class="line">        self._stats[spider.name <span class="keyword">if</span> spider <span class="keyword">else</span> <span class="keyword">None</span>][key] = value</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">set_stats</span><span class="params">(self, stats, spider=None)</span>:</span></div><div class="line">        self._stats[spider.name <span class="keyword">if</span> spider <span class="keyword">else</span> <span class="keyword">None</span>] = stats</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">inc_value</span><span class="params">(self, key, count=<span class="number">1</span>, start=<span class="number">0</span>, spider=None)</span>:</span></div><div class="line">        d = self._stats[spider.name <span class="keyword">if</span> spider <span class="keyword">else</span> <span class="keyword">None</span>]</div><div class="line">        d[key] = d.setdefault(key, start) + count</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">max_value</span><span class="params">(self, key, value, spider=None)</span>:</span></div><div class="line">        d = self._stats[spider.name <span class="keyword">if</span> spider <span class="keyword">else</span> <span class="keyword">None</span>]</div><div class="line">        d[key] = max(d.setdefault(key, value), value)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">min_value</span><span class="params">(self, key, value, spider=None)</span>:</span></div><div class="line">        d = self._stats[spider.name <span class="keyword">if</span> spider <span class="keyword">else</span> <span class="keyword">None</span>]</div><div class="line">        d[key] = min(d.setdefault(key, value), value)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">clear_stats</span><span class="params">(self, spider=None)</span>:</span></div><div class="line">        self._stats[spider.name <span class="keyword">if</span> spider <span class="keyword">else</span> <span class="keyword">None</span>].clear()</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">clear_all_stats</span><span class="params">(self)</span>:</span></div><div class="line">        self._stats.clear()</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span><span class="params">(self, spider)</span>:</span></div><div class="line">        loadpath = os.path.join(self.jobdir, <span class="string">'stats'</span>)</div><div class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(loadpath):</div><div class="line">            <span class="keyword">return</span></div><div class="line">        <span class="keyword">with</span> open(loadpath, <span class="string">'rb'</span>) <span class="keyword">as</span> f:</div><div class="line">            self._stats = pickle.load(f)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span><span class="params">(self, spider, reason)</span>:</span></div><div class="line">        dumppath = os.path.join(self.jobdir, <span class="string">'stats'</span>)</div><div class="line">        <span class="keyword">with</span> open(dumppath, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</div><div class="line">            pickle.dump(self._stats, f)</div><div class="line"></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">SpiderState</span><span class="params">(SpiderStateBase)</span>:</span></div><div class="line"><span class="meta">    @property</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">statefn</span><span class="params">(self)</span>:</span></div><div class="line">        statedir = os.path.join(</div><div class="line">            self.jobdir,</div><div class="line">            self.spider_name) <span class="keyword">if</span> self.spider_name <span class="keyword">else</span> self.jobdir</div><div class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(statedir):</div><div class="line">            os.makedirs(statedir)</div><div class="line">        <span class="keyword">return</span> os.path.join(statedir, <span class="string">'spider.state'</span>)</div><div class="line"></div><div class="line"><span class="meta">    @classmethod</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">from_crawler</span><span class="params">(cls, crawler)</span>:</span></div><div class="line">        obj = super(SpiderState, cls).from_crawler(crawler)</div><div class="line">        obj.spider_name = crawler.spidercls.name <span class="keyword">if</span> crawler.spidercls <span class="keyword">else</span> <span class="keyword">None</span></div><div class="line">        <span class="keyword">return</span> obj</div><div class="line"></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Scheduler</span><span class="params">(SchedulerBase)</span>:</span></div><div class="line"></div><div class="line"><span class="meta">    @classmethod</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">from_crawler</span><span class="params">(cls, crawler)</span>:</span></div><div class="line">        settings = crawler.settings</div><div class="line">        dupefilter_cls = load_object(settings[<span class="string">'DUPEFILTER_CLASS'</span>])</div><div class="line">        dupefilter = dupefilter_cls.from_crawler(crawler)</div><div class="line">        pqclass = load_object(settings[<span class="string">'SCHEDULER_PRIORITY_QUEUE'</span>])</div><div class="line">        dqclass = load_object(settings[<span class="string">'SCHEDULER_DISK_QUEUE'</span>])</div><div class="line">        mqclass = load_object(settings[<span class="string">'SCHEDULER_MEMORY_QUEUE'</span>])</div><div class="line">        logunser = settings.getbool(</div><div class="line">            <span class="string">'LOG_UNSERIALIZABLE_REQUESTS'</span>, settings.getbool(<span class="string">'SCHEDULER_DEBUG'</span>))</div><div class="line">        obj = cls(dupefilter, jobdir=job_dir(settings),</div><div class="line">                  logunser=logunser, stats=crawler.stats,</div><div class="line">                  pqclass=pqclass, dqclass=dqclass, mqclass=mqclass)</div><div class="line"></div><div class="line">        <span class="keyword">if</span> crawler.spidercls:</div><div class="line">            obj.spider_name = crawler.spidercls.name</div><div class="line">            obj.dqdir = obj._dqdir(job_dir(settings))</div><div class="line">        <span class="keyword">return</span> obj</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_dqdir</span><span class="params">(self, jobdir)</span>:</span></div><div class="line">        <span class="keyword">if</span> jobdir:</div><div class="line">            jobdir = os.path.join(</div><div class="line">                jobdir, self.spider_name) \</div><div class="line">                <span class="keyword">if</span> hasattr(self, <span class="string">'spider_name'</span>) <span class="keyword">else</span> jobdir</div><div class="line">            dqdir = os.path.join(jobdir, <span class="string">'requests.queue'</span>)</div><div class="line">            <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(dqdir):</div><div class="line">                os.makedirs(dqdir)</div><div class="line">            <span class="keyword">return</span> dqdir</div><div class="line"></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">RFPDupeFilter</span><span class="params">(RFPDupeFilterBase)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, path=None, debug=False, spider_name=None)</span>:</span></div><div class="line">        super(RFPDupeFilter, self).__init__(path=<span class="keyword">None</span>, debug=debug)</div><div class="line">        <span class="keyword">if</span> path:</div><div class="line">            <span class="keyword">if</span> spider_name:</div><div class="line">                path = os.path.join(path, spider_name)</div><div class="line">                <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(path):</div><div class="line">                    os.makedirs(path)</div><div class="line">            path = os.path.join(path, <span class="string">'requests.seen'</span>)</div><div class="line">            self.file = open(path, <span class="string">'a+'</span>)</div><div class="line">            self.file.seek(<span class="number">0</span>)</div><div class="line">            self.fingerprints.update(x.rstrip() <span class="keyword">for</span> x <span class="keyword">in</span> self.file)</div><div class="line"></div><div class="line"><span class="meta">    @classmethod</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">from_crawler</span><span class="params">(cls, crawler)</span>:</span></div><div class="line">        settings = crawler.settings</div><div class="line">        debug = settings.getbool(<span class="string">'BUPEFILTER_DEBUG'</span>)</div><div class="line">        <span class="keyword">return</span> cls(job_dir(settings), debug,</div><div class="line">                   crawler.spidercls.name <span class="keyword">if</span> crawler.spidercls <span class="keyword">else</span> <span class="keyword">None</span>)</div><div class="line"></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">LogStats</span><span class="params">(LogStatsBase)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">spider_opened</span><span class="params">(self, spider)</span>:</span></div><div class="line">        self.itemsprev = self.stats.get_value(</div><div class="line">            <span class="string">'item_scraped_count'</span>, <span class="number">0</span>, spider)</div><div class="line">        self.pagesprev = self.stats.get_value(</div><div class="line">            <span class="string">'response_received_count'</span>, <span class="number">0</span>, spider)</div><div class="line"></div><div class="line">        self.task = task.LoopingCall(self.log, spider)</div><div class="line">        self.task.start(self.interval)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">log</span><span class="params">(self, spider)</span>:</span></div><div class="line">        LogStatslogger = logging.getLogger(spider.name)</div><div class="line"></div><div class="line">        items = self.stats.get_value(<span class="string">'item_scraped_count'</span>, <span class="number">0</span>, spider)</div><div class="line">        pages = self.stats.get_value(<span class="string">'response_received_count'</span>, <span class="number">0</span>, spider)</div><div class="line">        irate = (items - self.itemsprev) * self.multiplier</div><div class="line">        prate = (pages - self.pagesprev) * self.multiplier</div><div class="line">        self.pagesprev, self.itemsprev = pages, items</div><div class="line"></div><div class="line">        msg = (<span class="string">"Crawled %(pages)d pages (at %(pagerate)d pages/min), "</span></div><div class="line">               <span class="string">"scraped %(items)d items (at %(itemrate)d items/min)"</span>)</div><div class="line">        log_args = &#123;<span class="string">'pages'</span>: pages, <span class="string">'pagerate'</span>: prate,</div><div class="line">                    <span class="string">'items'</span>: items, <span class="string">'itemrate'</span>: irate&#125;</div><div class="line">        LogStatslogger.info(msg, log_args, extra=&#123;<span class="string">'spider'</span>: spider&#125;)</div></pre></td></tr></table></figure>
<!-- markdownlint-enable MD022 MD026 MD012 -->
<p>把以上代码保存到根目录下的<code>ext\__init__.py</code>中，最后修改设置<br><!-- markdownlint-disable MD022 MD026 --></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># settings.py...</span></div><div class="line">DUPEFILTER_CLASS = <span class="string">'myproject.ext.RFPDupeFilter'</span></div><div class="line">SCHEDULER = <span class="string">'myproject.ext.Scheduler'</span></div><div class="line">EXTENSIONS_BASE = &#123;</div><div class="line">    <span class="string">'myproject.ext.LogStats'</span>: <span class="number">0</span>,</div><div class="line">    <span class="string">'myproject.ext.SpiderState'</span>: <span class="number">0</span>,</div><div class="line">    <span class="string">'scrapy.extensions.corestats.CoreStats'</span>: <span class="number">0</span>,</div><div class="line">    <span class="string">'scrapy.extensions.telnet.TelnetConsole'</span>: <span class="number">0</span>,</div><div class="line">    <span class="string">'scrapy.extensions.memusage.MemoryUsage'</span>: <span class="number">0</span>,</div><div class="line">    <span class="string">'scrapy.extensions.memdebug.MemoryDebugger'</span>: <span class="number">0</span>,</div><div class="line">    <span class="string">'scrapy.extensions.closespider.CloseSpider'</span>: <span class="number">0</span>,</div><div class="line">    <span class="string">'scrapy.extensions.feedexport.FeedExporter'</span>: <span class="number">0</span>,</div><div class="line">    <span class="string">'scrapy.extensions.throttle.AutoThrottle'</span>: <span class="number">0</span>,</div><div class="line">&#125;</div><div class="line"><span class="comment"># ...</span></div></pre></td></tr></table></figure>
<!-- markdownlint-enable MD022 MD026 -->
<p>现在运行<code>scrapy runallspider</code>就没问题了，暂停，等下次重新启动也就能恢复到原来的爬虫状态。</p>
<h1 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h1><p><strong>Scrapy</strong>是一个十分强大且支持扩展的爬虫框架</p>
<ol>
<li><strong>template</strong>模板,让我们少写了许多代码;</li>
<li><strong>command</strong>自定命令,让我们可以偷懒 :) ；</li>
<li><strong>job</strong> <strong>Spider</strong>的暂停\恢复,这个功能太强大了。<br> 不仅只是保存<strong>Spider</strong>这几类状态，比如说通过重载<strong>pipeline</strong>中的<br><code>open_spider(spider)</code>和<code>closed_spider(spider)</code>方法,来保存<strong>pipeline</strong>的状态，以供下次恢复</li>
</ol>

      
    </div>

    
      
      

  <div class="post-copyright">
    <p class="copyright-item">
      <span>Author: </span>
      <span>linw</span>
    </p>
    <p class="copyright-item">
      <span>Origin: </span>
      <a href="http://linw1995.com">http://linw1995.com</a>
    </p>
    <p class="copyright-item">
      <span>Link: </span>
      <a href="http://linw1995.com/2017/04/15/Scrapy学习日记-一-·-run-many-spiders/">http://linw1995.com/2017/04/15/Scrapy学习日记-一-·-run-many-spiders/</a>
    </p>

    <p class="copyright-item lincese">
      
      本文采用<a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/" target="_blank">知识共享署名-非商业性使用 4.0 国际许可协议</a>进行许可
    </p>
  </div>



      
      
  <div class="post-reward">
    <input type="checkbox" name="reward" id="reward" hidden />
    <label class="reward-button" for="reward">Reward</label>
    <div class="qr-code">
      
      
        <label class="qr-code-image" for="reward">
          <img class="image" src="/image/reward/wechat.png" title="wechat">
        </label>
      
      
    </div>
  </div>

    

    
      <footer class="post-footer">
        
          <div class="post-tags">
            
              <a href="/tags/Python/">Python</a>
            
              <a href="/tags/Scrapy/">Scrapy</a>
            
          </div>
        
        
        
  <nav class="post-nav">
    
    
      <a class="next" href="/2017/04/12/折腾VSCode记-二-·-Settings-Sync/">
        <span class="next-text nav-default">折腾VSCode记 二 · Settings Sync</span>
        <span class="prev-text nav-mobile">Next</span>
        <i class="iconfont icon-right"></i>
      </a>
    
  </nav>

      </footer>
    

  </article>


          </div>
          
  <div class="comments" id="comments">
    
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    
  </div>


        </div>  
      </main>

      <footer id="footer" class="footer">

  <div class="social-links">
    
      
        
          <a href="mailto:linw1995@icloud.com" class="iconfont icon-email" title="email"></a>
        
      
    
      
    
      
    
      
    
      
    
      
    
      
        
          <a href="https://github.com/linw1995" class="iconfont icon-github" title="github"></a>
        
      
    
      
        
          <a href="http://weibo.com/R34DM3" class="iconfont icon-weibo" title="weibo"></a>
        
      
    
      
    
      
    
    
    
      <a href="/atom.xml" class="iconfont icon-rss" title="rss"></a>
    
  </div>


<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://hexo.io/">Hexo</a>
  </span>
  
  <span class="theme-info">
    Theme - 
    <a class="theme-link" href="https://github.com/ahonn/hexo-theme-even">Even</a>
  </span>

  <span class="copyright-year">
    
    &copy; 
     
      2015 - 
    
    2017

    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">linw</span>
  </span>
</div>
      </footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>

    
  

  
  <script type="text/javascript">
    var disqus_config = function () {
        this.page.url = 'http://linw1995.com/2017/04/15/Scrapy学习日记-一-·-run-many-spiders/';
        this.page.identifier = '2017/04/15/Scrapy学习日记-一-·-run-many-spiders/';
        this.page.title = 'Scrapy学习日记 一 · run many spiders';
    };
    (function() {
    var d = document, s = d.createElement('script');

    s.src = '//linw1995.disqus.com/embed.js';

    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
    })();  
  </script>

  




    
  





  
    <script type="text/javascript" src="/lib/jquery/jquery-3.1.1.min.js"></script>
  

  
    <script type="text/javascript" src="/lib/slideout/slideout.js"></script>
  

  
    <script type="text/javascript" src="/lib/fancybox/jquery.fancybox.pack.js"></script>
  


    <script type="text/javascript" src="/js/src/even.js?v=2.3.x"></script>
<script type="text/javascript" src="/js/src/bootstrap.js?v=2.3.x"></script>

    
  </body>
</html>
