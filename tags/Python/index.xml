<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Python on linw1995</title>
    <link>https://linw1995.com/tags/Python/</link>
    <description>Recent content in Python on linw1995</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-US</language>
    <lastBuildDate>Sun, 04 Aug 2019 23:59:59 +0000</lastBuildDate>
    
	<atom:link href="https://linw1995.com/tags/Python/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>用 docker-compose 部署 MongoDB Replica Set 开发环境</title>
      <link>https://linw1995.com/blog/%E7%94%A8-docker-compose-%E9%83%A8%E7%BD%B2-MongoDB-Replica-Set-%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/</link>
      <pubDate>Sun, 04 Aug 2019 23:59:59 +0000</pubDate>
      
      <guid>https://linw1995.com/blog/%E7%94%A8-docker-compose-%E9%83%A8%E7%BD%B2-MongoDB-Replica-Set-%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/</guid>
      <description>前言 话不多说，直接进正题
如何搭建和配置 把以下内容写入 docker-compose.yml 文件中。然后运行 docker-compose up -d --scale mongo=3，就可以启动三个 MongoDB 服务。接下来我们要把这三个 MongoDB 节点配置成一组 Replica Set
version: &amp;#39;3.5&amp;#39; services: mongo: image: mongo ports: - &amp;#34;27017-27118:27017&amp;#34; command: mongod --replSet main 把以下内容写入 utils.py 文件中
import subprocess as sp def get_node_ports(): ports = [] idx = 1 while True: try: output = sp.check_output( f&amp;#34;docker-compose port --index {idx} mongo 27017&amp;#34;, shell=True, encoding=&amp;#34;utf-8&amp;#34;, stderr=sp.DEVNULL, ) except sp.CalledProcessError: break port = output.split(&amp;#34;:&amp;#34;)[1] ports.append(int(port)) idx += 1 if not ports: raise RuntimeError(&amp;#34;no node is running.</description>
    </item>
    
    <item>
      <title>Scrapy 的并发处理</title>
      <link>https://linw1995.com/blog/Scrapy-%E7%9A%84%E5%B9%B6%E5%8F%91%E5%A4%84%E7%90%86/</link>
      <pubDate>Mon, 29 Jul 2019 23:59:59 +0000</pubDate>
      
      <guid>https://linw1995.com/blog/Scrapy-%E7%9A%84%E5%B9%B6%E5%8F%91%E5%A4%84%E7%90%86/</guid>
      <description>前言 看大型项目的源码时，经常摸不着头脑，耗时但收益少，所以也就不容易坚持下去。但如果带着问题来看的话，屏蔽掉问题无关的代码，专注于相关的，看看能不能真正的从源码中学习到好东西
问题: Scrapy 的并发处理 在 Scrapy 的文档中提到可以通过配置 DOWNLOAD_DELAY 来控制请求（request）间的时间间隔，配置 CONCURRENT_REQUESTS 来限制请求（request）的并发数（粒度可基于域名，或者 IP 地址）。甚至可以通过使用 Auto-Throttling 自动节流插件，来自动地且动态的调整这些配置项。
这样我们就有了以下这两个问题
 如何并发地处理请求 如何动态地改变配置项  以下的源码分析基于版本号为 1.7.2 的 scrapy 项目
如何并发地处理请求 scrapy/core/downloader/__init__.pyL138-L160 里的 Downloader 类的类方法 _process_queue 就负责处理 scrapy 的并发请求
为了更好的理解这函数的代码，首先要确定什么情况下 _process_queue 才会被调用
 当新的请求进入队列时 L135 当请求完成网络处理时 L186 当不满足 DONWLOAD_DELAY 时的延迟调用 L148  以下就是该函数的代码，加上了些注释方便大家理解
def _process_queue(self, spider, slot): if slot.latercall and slot.latercall.active(): # 由于同个 slot 会被 _process_queue 重复调用多次，情况 1，2 # 当情况 3 在处理时，则不执行 return # Delay queue processing if a download_delay is configured now = time() # 获取下载延迟，若是启用了 randomize_delay 则每次会获取到不同的下载延迟 delay = slot.</description>
    </item>
    
    <item>
      <title>用多线程加速爬虫的 lxml 解析</title>
      <link>https://linw1995.com/blog/%E7%94%A8%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%8A%A0%E9%80%9F%E7%88%AC%E8%99%AB%E7%9A%84-lxml-%E8%A7%A3%E6%9E%90/</link>
      <pubDate>Wed, 17 Jul 2019 23:59:59 +0000</pubDate>
      
      <guid>https://linw1995.com/blog/%E7%94%A8%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%8A%A0%E9%80%9F%E7%88%AC%E8%99%AB%E7%9A%84-lxml-%E8%A7%A3%E6%9E%90/</guid>
      <description>当编写一个爬虫时，会使用 lxml 库来解析 HTML 文件。当爬取到了一个超大且复杂的 HTML 文件，解析起来十分耗费时间，进而影响了爬虫的正常运行
为了不影响爬虫的正常运行，尝试把解析任务交给线程池来处理
模拟爬虫 先随便准备一个 html 文件，就直接从 lxml 的文档上下载一个
wget https://lxml.de/tutorial.html -O example.html 举一个重解析的模拟爬虫例子，每次请求的 io 时间假定为 0.01s ，请求并发数无上限，总量为 2000 个。
import asyncio import time from pathlib import Path from lxml import html _html_text = None _latest_fetched = 0 async def fetch_text(): # 模拟爬取 await asyncio.sleep(0.01) # 记录最后的一个请求的结束时间 global _latest_fetched _latest_fetched = time.perf_counter() return _html_text def get_title(text): doc = html.fromstring(text) return doc.xpath(&amp;#34;//title/text()&amp;#34;)[0] async def create_task(): text = await fetch_text() title = get_title(text) return title async def main(): futs = [] for _ in range(2000): fut = asyncio.</description>
    </item>
    
    <item>
      <title>两种方式来用 Python logging 记录额外的值</title>
      <link>https://linw1995.com/blog/%E4%B8%A4%E7%A7%8D%E6%96%B9%E5%BC%8F%E6%9D%A5%E7%94%A8-Python-logging-%E8%AE%B0%E5%BD%95%E9%A2%9D%E5%A4%96%E7%9A%84%E5%80%BC/</link>
      <pubDate>Tue, 29 Jan 2019 23:59:59 +0000</pubDate>
      
      <guid>https://linw1995.com/blog/%E4%B8%A4%E7%A7%8D%E6%96%B9%E5%BC%8F%E6%9D%A5%E7%94%A8-Python-logging-%E8%AE%B0%E5%BD%95%E9%A2%9D%E5%A4%96%E7%9A%84%E5%80%BC/</guid>
      <description>前言 有两种方式来用 Python logging 记录额外的值
 使用 extra 参数 向 args 传入字典结构的数据  使用 extra 参数 通过 log 方法的 extra 参数可以来记录而外的值。通过 LogRecord.extra 获取，配合 LogFilter 及 LoggerAdapter 使用。还可以通过配置 Formatter 打印出该值
logging.basicConfig(format=&amp;#34;%(ip)s- %(message)s&amp;#34;) logging.info(&amp;#34;test message&amp;#34;, extra={&amp;#34;ip&amp;#34;: &amp;#34;127.0.0.1&amp;#34;}) 其输出
127.0.0.1 - test message 使用 Formatter 十分方便，但一旦没有通过 extra 传入对应的键值，则会导致日志写出异常
logger = logging.getLogger() adapted_logger = logging.LoggerAdapter(logger, extra={&amp;#34;ip&amp;#34;: &amp;#34;127.0.0.1&amp;#34;}) adapted_logger.info(&amp;#34;test message&amp;#34;) 可通过 LoggerAdapter 来给所有 log 方法加上 extra 参数
不过官方的实现很奇怪，直接覆盖掉了原本的 extra 参数。
 LoggerAdapter.process LoggerAdapter.log  通过继承它，修改 process 方法即可</description>
    </item>
    
    <item>
      <title>Run Twisted in another thread</title>
      <link>https://linw1995.com/blog/Run-Twisted-in-another-thread/</link>
      <pubDate>Thu, 27 Dec 2018 23:59:59 +0000</pubDate>
      
      <guid>https://linw1995.com/blog/Run-Twisted-in-another-thread/</guid>
      <description>Develop a project related to a service project base on Twisted, and consider how to test it. This is a solution. Run Twisted&#39;s reactor in another thread and delegating the Twisted functions calling into it.
Use this fixture run a reactor in another thread. Due to the reactor is not restartable, so the fixture&#39;s scope is &amp;ldquo;session&amp;rdquo;.
import pytest from twisted.internet import reactor as twisted_reactor @pytest.fixture(scope=&amp;#34;session&amp;#34;, autouse=True) def reactor(): t = threading.</description>
    </item>
    
    <item>
      <title>Python 版本及依赖管理的最终方案 pyenv &#43; Pipenv</title>
      <link>https://linw1995.com/blog/Python-%E7%89%88%E6%9C%AC%E5%8F%8A%E4%BE%9D%E8%B5%96%E7%AE%A1%E7%90%86%E7%9A%84%E6%9C%80%E7%BB%88%E6%96%B9%E6%A1%88-pyenv-Pipenv/</link>
      <pubDate>Sat, 22 Dec 2018 22:45:00 +0000</pubDate>
      
      <guid>https://linw1995.com/blog/Python-%E7%89%88%E6%9C%AC%E5%8F%8A%E4%BE%9D%E8%B5%96%E7%AE%A1%E7%90%86%E7%9A%84%E6%9C%80%E7%BB%88%E6%96%B9%E6%A1%88-pyenv-Pipenv/</guid>
      <description>前言 作为个程序员，总会遇到这些问题：如何升级系统的 Python 版本；如何安装多个 Python 版本；如何隔离项目的依赖；在开发机上好好的，为什么线上、CI 就运行失败了呢
 通过下载 Python 源码编译安装（最好不要覆盖掉系统原有的 Python，可安装在自己的 home 目录或者其他路径下） 通过 Virtualenv 来隔离项目 Python 环境 通过 pip freeze &amp;gt; requirements.txt 和 pip install -r requirements.txt来固定依赖的版本，来确保重新安装后的 Python 环境是一致  随着开发项目的增多，mac 上的 Python 环境越来越复杂，就像下面这张图一样。面对这样的复杂的环境，管理起来太折磨人了，且会因冗余而浪费硬盘空间。
![版本及依赖管理指北](/blog/Python 版本及依赖管理的最终方案 pyenv + Pipenv/01.png)
那么我们如何来管理越来越复杂的 Python 环境？解决该问题的最终方案是：使用 pyenv 管理多个 python 版本；使用 Pipenv 管理项目所需要的依赖。
pyenv Github Repo: pyenv/pyenv
参照此教程安装 pyenv
 installation | pyenv
 使用
pyenv install --list # 列出所有可安装的版本 pyenv install 3.7.1 # 安装指定版本 pyenv shell 3.</description>
    </item>
    
    <item>
      <title>自己来写压缩算法——LZW</title>
      <link>https://linw1995.com/blog/%E8%87%AA%E5%B7%B1%E6%9D%A5%E5%86%99%E5%8E%8B%E7%BC%A9%E7%AE%97%E6%B3%95LZW/</link>
      <pubDate>Tue, 24 Oct 2017 08:52:58 +0000</pubDate>
      
      <guid>https://linw1995.com/blog/%E8%87%AA%E5%B7%B1%E6%9D%A5%E5%86%99%E5%8E%8B%E7%BC%A9%E7%AE%97%E6%B3%95LZW/</guid>
      <description>之前用哈夫曼算法，把固定长的字符编码根据其出现次数，编码为不固定长的编码。而这次介绍的算法恰恰相反，该算法是把不等长的字符串，编码为固定长的编码。
LZW 蓝博-立夫-卫曲编码法（Lempel-Ziv-Welch，缩写LZW），是亚伯拉罕·蓝波、杰可布·立夫与泰瑞·卫曲共同提出的一种无损数据压缩演算法。与霍夫曼编码相比，LZW把不同长度的字符串转换为固定长的编码。该方法不需要事先对数据做任何分析，所以可以流式地对文件进行处理。
原理 编码 举个简单的例子，如果有一份数据，内容中的字符只有&#39;abc&#39;三种。那么如何对它进行编码呢？
首先先将单字符建立成一个字符串编码表，分别给予编号。
| string | code | |--------|------| | a | 0 | | b | 1 | | c | 2 | 若数据为aabcaac，进过LZW编码后结果为 [0,0,1,2,3,2,]，过程如下
| No. | cur | prefix | prefix + cur | in str-&amp;gt;code | code | add into str-&amp;gt;code | | --- | --- | ------ | ------------ | ------------ | ---- | ------------------ | | 1 | a | | a | true | | | | 2 | a | a | aa | false | 0 | aa -&amp;gt; 3 | | 3 | b | a | ab | false | 0 | ab -&amp;gt; 4 | | 4 | c | b | bc | false | 1 | bc -&amp;gt; 5 | | 5 | a | c | ca | false | 2 | ca -&amp;gt; 6 | | 6 | a | a | aa | true | | | | 7 | c | aa | aac | false | 3 | aac -&amp;gt; 7 | | 8 | | c | | | 2 | | 整个算法过程如下：</description>
    </item>
    
    <item>
      <title>自己来写压缩算法——哈夫曼算法</title>
      <link>https://linw1995.com/blog/%E8%87%AA%E5%B7%B1%E6%9D%A5%E5%86%99%E5%8E%8B%E7%BC%A9%E7%AE%97%E6%B3%95%E5%93%88%E5%A4%AB%E6%9B%BC%E7%AE%97%E6%B3%95/</link>
      <pubDate>Sun, 24 Sep 2017 22:24:08 +0000</pubDate>
      
      <guid>https://linw1995.com/blog/%E8%87%AA%E5%B7%B1%E6%9D%A5%E5%86%99%E5%8E%8B%E7%BC%A9%E7%AE%97%E6%B3%95%E5%93%88%E5%A4%AB%E6%9B%BC%E7%AE%97%E6%B3%95/</guid>
      <description>一般文件的编码都是等长的，一些常用字符的编码与很少用到的等长，可若是编码是变长的呢？无疑可以使整个文件大小减小。为了解码时不遇到任何歧义的问题，则每个有效字符所代表的变长编码不能是其它字符的前缀，这种编码也叫做前缀编码。而如何做到这一点呢，接下的内容会尽可能地讲明白。
哈夫曼算法 若是把等长的编码(一字节)用平衡二叉树来表示，字符共有256个，那么树的深度就有 $\log_{2}{256}=8$ 。
如果变作变长编码，那么所有有儿子（child）的节点（node）都不能用来表示，唯有子叶（leaf，没有儿子的节点）才可以用来表示。这是因为每个有效字符所代表的变长编码不能是其它字符的前缀。而且树结构也不可能是平衡二叉树了，树的深度肯定会大于8。
例如，有一份MIT-LICENCE.txt文件，其中空格&#39; &#39;有163个，而字母&#39;v&#39;却只有一个。那么让&#39; &#39;表示为110,&#39;v&#39;表示为0111011101，那么得省$(8 - 3) \times 163 - (8 - 10) \times 1 = 817$个bit。可见变长编码确确实实能起到压缩的作用。
哈夫曼树 哈夫曼树Huffman Tree，也叫做最优二叉树，是一种带权路径长度最短的二叉树。所谓树的带权路径长度，就是树中所有的叶结点的权值乘上其到根结点的路径长度（若根结点为$0$层，叶结点到根结点的路径长度为叶结点的层数）。树的路径长度是从树根到每一结点的路径长度之和，记为$\operatorname{WPL}=(W_1 \times L_ 1+W_2 \times L_2+W_3 \times L_3+&amp;hellip;+W_n \times L_n)$，$N$个权值$W_i(i=1,2,&amp;hellip;n)$构成一棵有$N$个叶结点的二叉树，相应的叶结点的路径长度为$L_i(i=1,2,&amp;hellip;n)$。可以证明霍夫曼树的$\operatorname{WPL}$是最小的。
/-40 /-40 /-40 /-| /-| /-| | \-48 | \-48 | | /-48 --| | | \-| | /-60 --| /-60 --| \-18 \-| | /-| | | /-30 | | \-20 | /-60 \-| \-| | /-| | /-18 | /-30 \-| \-20 \-| \-| | \-20 \-18 \-30 (0) (1) (2) 计算上面三颗树的$\operatorname{WPL}$：</description>
    </item>
    
    <item>
      <title>初解Python并发</title>
      <link>https://linw1995.com/blog/%E5%88%9D%E8%A7%A3Python%E5%B9%B6%E5%8F%91/</link>
      <pubDate>Sun, 16 Jul 2017 21:28:07 +0000</pubDate>
      
      <guid>https://linw1995.com/blog/%E5%88%9D%E8%A7%A3Python%E5%B9%B6%E5%8F%91/</guid>
      <description>前言 昨天（2017年7月15日）偶然看到这个视频，看完之后豁然开朗，忍不住要分享给大家。
  并发Demo 视频中举了个例子，用socket写了个迷你服务，只有一个作用，计算Fibonacci……
# -*- coding: utf-8 -*- # server.py import socketdef fib(n):if n &amp;lt;= 2:return 1else:return fib(n - 1) + fib(n - 2)def server(addr, port):sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)sock.bind((addr, port))sock.listen(5)while True:client, addr = sock.accept()print(&amp;#39;Connection&amp;#39;, addr)handler(client)def handler(client):while True:req = client.recv(100)if not req:breakn = int(req)result = fib(n)resp = str(result).</description>
    </item>
    
    <item>
      <title>蒙特卡洛方法及应用</title>
      <link>https://linw1995.com/blog/%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E6%96%B9%E6%B3%95%E5%8F%8A%E5%BA%94%E7%94%A8/</link>
      <pubDate>Sun, 21 May 2017 03:03:20 +0000</pubDate>
      
      <guid>https://linw1995.com/blog/%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E6%96%B9%E6%B3%95%E5%8F%8A%E5%BA%94%E7%94%A8/</guid>
      <description>蒙特卡洛方法（英语：Monte Carlo method），也称统计模拟方法，是1940年代中期由于科学技术的发展和电子计算机的发明，而提出的一种以概率统计理论为指导的数值计算方法。是指使用随机数（或更常见的伪随机数）来解决很多计算问题的方法。
20世纪40年代，在冯·诺伊曼，斯塔尼斯拉夫·乌拉姆和尼古拉斯·梅特罗波利斯在洛斯阿拉莫斯国家实验室为核武器计划工作时，发明了蒙特卡洛方法。因为乌拉姆的叔叔经常在摩纳哥的蒙特卡洛赌场输钱得名，而蒙特卡罗方法正是以概率为基础的方法。
与它对应的是确定性算法。
蒙特卡洛方法在金融工程学，宏观经济学，生物医学，计算物理学（如粒子输运计算、量子热力学计算、空气动力学计算）等领域应用广泛。
 基本思想 把所求解的问题转换为某种随机分布的特征数，例如随机事件出现的概率，或者随机变量的期望值。通过随机抽样的方法，以随机事件出现的频率估计其概率，或者一抽样的数字特征估算随机变量的数学特征，并将其作为问题的解。
应用 求解圆周率 圆形的面积为$A_s=\pi r^2$，正方形的面积为$A_q=(2r)^2$, 则产生一对随机数$(x_i, y_i)$落在圆内的概率为： $$ p=\frac{A_s}{A_q}=\frac{\pi r^2}{(2r)^2}=\frac{\pi}{4} $$ 只要不断产生一对对随机数$(x_i, y_i)$，由于大数法则（Law of large numbers），能以随机事件（落在圆内）出现的频率估计其概率，再求解$\pi$。
 代码 Gist | Monte Carlo method applied to approximating the value of π.
 计算定积分 假设我们要求解$f(x)=x^2$在$[0, 2]$间的积分，即下图函数曲线与$x$轴围成的面积
其实，求解圆周率其实是在求函数$f(x)=\sqrt{1 - x^2}$在区间$[0, 1]$上的积分。
偶然命中法 像求解圆周率那样，只要求解出一对随机数$(x_i,y_i),x_i\in[0,2],y_i\in[0,4]$落在曲线下方的概率，即可求出$f(x)=x^2$在$[0, 2]$间的积分结果。 $$H(x, y)=\begin{cases}1\qquad&amp;amp;if\quad y \le f(x) \\0 &amp;amp;else\end{cases}\\F_n=A \frac{1}{n} \sum^{n}_{i=1} H(x_i,y_i) = h(b-a) \frac{1}{n}\sum^{n}_{i=1} H(x_i,y_i)$$抽样平均法 还有另外一种蒙特卡罗积分方法是基于计算的平均值理论，即函数的积分结果取决被积函数$f(x)$在$a\le x\le b$的平均值。为了确定这个平均值，用随机的$x_i$来取代规律的$x_i$，抽样平均值方法的积分估计值$F_n$为： $$ F_n=(b-a)\left\lt f\right\gt=\frac{b-a}{n}\sum^n_{i=1}f(x_i) $$</description>
    </item>
    
    <item>
      <title>伪随机数</title>
      <link>https://linw1995.com/blog/%E4%BC%AA%E9%9A%8F%E6%9C%BA%E6%95%B0/</link>
      <pubDate>Fri, 05 May 2017 22:42:12 +0000</pubDate>
      
      <guid>https://linw1995.com/blog/%E4%BC%AA%E9%9A%8F%E6%9C%BA%E6%95%B0/</guid>
      <description>序  伪随机性（英语：Pseudorandomness）是指一个过程似乎是随机的，但实际上并不是。例如伪随机数（或称伪乱数），是使用一个确定性的算法计算出来的似乎是随机的数序，因此伪随机数实际上并不随机。在计算伪随机数时假如使用的开始值不变的话，那么伪随机数的数序也不变。伪随机数的随机性可以用它的统计特性来衡量，其主要特征是每个数出现的可能性和它出现时与数序中其它数的关系。伪随机数的优点是它的计算比较简单，而且只使用少数数值很难推算出计算它的算法。一般人们使用一个假的随机数，比如电脑上的时间作为计算伪随机数的开始值。
 产生随机数的方法  线性同余法 平方取中法 M-Sequence 梅森旋转算法 伪随机数二进制数列  其中使用最多的是线性同余法和梅森旋转算法，下面主要介绍一下线性同余法
线性同余法（LCG linear congruential generator） 线性同余方法（LCG）是个产生伪随机数的方法。 它是根据递归公式： $$N_{j+1}\equiv (A\times N_{j}+C){\pmod {M}}$$ 其中$A,C,M$是产生器设定的常数。
Python implementation class Random:def __init__(self, A, C, M, seed=0):self._A = Aself._C = Cself._M = Mself._prev = seed % Mdef __call__(self):A = self._AC = self._CM = self._Mprev = self._prevcur = self._prev = (A * prev + C) % Mreturn cur / Mdef __repr__(self):return &amp;#39;Random(A={obj.</description>
    </item>
    
    <item>
      <title>AA树的平衡与再平衡</title>
      <link>https://linw1995.com/blog/AA%E6%A0%91%E7%9A%84%E5%B9%B3%E8%A1%A1%E4%B8%8E%E5%86%8D%E5%B9%B3%E8%A1%A1/</link>
      <pubDate>Thu, 27 Apr 2017 12:38:13 +0000</pubDate>
      
      <guid>https://linw1995.com/blog/AA%E6%A0%91%E7%9A%84%E5%B9%B3%E8%A1%A1%E4%B8%8E%E5%86%8D%E5%B9%B3%E8%A1%A1/</guid>
      <description>介绍  AA树在计算机科学一种形式的自平衡二叉查找树用于高效存储和检索序数据。AA树的名称是由它的发明者Arne Andersson而来。 AA树是红黑树的一种变种，是Arne Andersson教授在1993年年在他的论文*&amp;ldquo;Balanced search trees made simple&amp;rdquo;*中介绍，设计的目的是减少**红黑树**考虑的不同情况，区别于**红黑树**的是，**AA树**的红节点只能作为右叶子。换句话说，没有红节点可以是一个左子儿。这导致代替**2-3-4树**，从而大大简化了维护**2-3树**的模拟。维护**红黑树**的平衡需要考虑7种不同的情况:
  因为AA树有严格的条件(红节点只能为右节点)，故只需考虑2种情形:
 AA树是2-3树的模拟，2-3树和AA树是等距同构的。其节点类型如下
平衡条件 树是用与高效的存储和检索数据的，为了维持其效率，必须维持其平衡结构。 平衡一颗红黑树需记录其颜色，而AA树是在每个节点记录其level这相当于红黑树节点的黑高度
 所有叶节点的level都是1 每个左孩子的level恰好为其父亲的level减一 每个右孩子的level等于其父亲的level或为其父亲的level减一 每个右孙子的level严格小于其祖父节点的level 每一个level大于1的节点有两个子节点  Skew &amp;amp; Split 对于AA树，维持其平衡的基本操作如下：
  偏斜Skew：使得子树中向左的水平边变成向右的。
不满足平衡条件：2
def skew(node):if node is None or node.left is None:return nodeif node.left.level != node.level:return nodelft = node.leftnode.left = lft.right # B =&amp;gt; C change to D =&amp;gt; C lft.right = node # D =&amp;gt; B change to B =&amp;gt; D return lft # top =&amp;gt; D change to top =&amp;gt; B  判断是否是偏斜 i.</description>
    </item>
    
  </channel>
</rss>