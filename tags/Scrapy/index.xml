<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Scrapy on linw1995</title>
    <link>https://linw1995.com/tags/Scrapy/</link>
    <description>Recent content in Scrapy on linw1995</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Mon, 29 Jul 2019 23:59:59 +0000</lastBuildDate>
    
	<atom:link href="https://linw1995.com/tags/Scrapy/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Scrapy 的并发处理</title>
      <link>https://linw1995.com/blog/Scrapy-%E7%9A%84%E5%B9%B6%E5%8F%91%E5%A4%84%E7%90%86/</link>
      <pubDate>Mon, 29 Jul 2019 23:59:59 +0000</pubDate>
      
      <guid>https://linw1995.com/blog/Scrapy-%E7%9A%84%E5%B9%B6%E5%8F%91%E5%A4%84%E7%90%86/</guid>
      <description>前言 看大型项目的源码时，经常摸不着头脑，耗时但收益少，所以也就不容易坚持下去。但如果带着问题来看的话，屏蔽掉问题无关的代码，专注于相关的，看看能不能真正的从源码中学习到好东西
问题: Scrapy 的并发处理 在 Scrapy 的文档中提到可以通过配置 DOWNLOAD_DELAY 来控制请求（request）间的时间间隔，配置 CONCURRENT_REQUESTS 来限制请求（request）的并发数（粒度可基于域名，或者 IP 地址）。甚至可以通过使用 Auto-Throttling 自动节流插件，来自动地且动态的调整这些配置项。
这样我们就有了以下这两个问题
 如何并发地处理请求 如何动态地改变配置项  以下的源码分析基于版本号为 1.7.2 的 scrapy 项目
如何并发地处理请求 scrapy/core/downloader/__init__.pyL138-L160 里的 Downloader 类的类方法 _process_queue 就负责处理 scrapy 的并发请求
为了更好的理解这函数的代码，首先要确定什么情况下 _process_queue 才会被调用
 当新的请求进入队列时 L135 当请求完成网络处理时 L186 当不满足 DONWLOAD_DELAY 时的延迟调用 L148  以下就是该函数的代码，加上了些注释方便大家理解
def _process_queue(self, spider, slot): if slot.latercall and slot.latercall.active(): # 由于同个 slot 会被 _process_queue 重复调用多次，情况 1，2 # 当情况 3 在处理时，则不执行 return # Delay queue processing if a download_delay is configured now = time() # 获取下载延迟，若是启用了 randomize_delay 则每次会获取到不同的下载延迟 delay = slot.</description>
    </item>
    
  </channel>
</rss>